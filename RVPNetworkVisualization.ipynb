{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #noqa: F401\n",
    "import numpy as np #noqa: F401\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime  ###, timedelta, timezone\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from pathlib import Path\n",
    "import phonenumbers\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Common/')\n",
    "from empowerJSONhelpers import InitializeDataFrames, beginningOfTime\n",
    "from edatools import ColumnMove, IsBlank, IsNotBlank #noqa: F40\n",
    "\n",
    "startDate = '2024-04-01 00:00:00'\n",
    "campaignStartDate = datetime.fromisoformat(startDate).date()\n",
    "\n",
    "## profile-<date>.csv is a dump of the Empower data.  I store these on the N: drive\n",
    "today = '24-9-24'\n",
    "home = 'N:/'\n",
    "path = home + 'Al/RelationalVoterProgram/Python/ReadEmpowerData_2024/'\n",
    "data_file = 'Profiles/profiles-' + today + '.csv'\n",
    "\n",
    "organizers = ['Director', 'Organizer', 'Volunteer']\n",
    "voters = ['Contact']\n",
    "regions = ['Green Bay', 'Kenosha', 'Racine', 'Madison', 'Milwaukee', 'Manitowoc', 'Sheboygan',\n",
    "    'Walworth', 'Waukesha', 'Unknown Region']\n",
    "\n",
    "startDate24 = '2024-04-01'\n",
    "campaignStartDate24 = datetime.fromisoformat(startDate24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names and EID's of organizers who are no longer with us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "departed_eids = [\\\n",
    "'u-56-3016',  # Al Nichols\n",
    "'u-56-18093', # Fabi,\n",
    "'u-56-21557', # Jake Pena\n",
    "'sZONfFaf3OOHvz', # Gilbert Nunez\n",
    "'idKoO5r7j1gFxv', # Emily Firlinger\n",
    "'rboft4TAXwHySN', # Jennifer Estrada\n",
    "'Ya6XAA9GBhi8Kl', # Dummy Account\n",
    "'bqUNmQHKI3w5AZ', # Ray Pugh\n",
    "'FAzpkk9IzXrbt6', # Clay Perry\n",
    "'u-56-21623',     # Allison Vasquez-Lovell\n",
    "'1oRrlB5DWlbmxz', # Jose Rivera\n",
    "'m4pozco9m8exul', # Ruben Ramos\n",
    "'TBNKT6PmgtvmOB', # Minerva Cornejo\n",
    "'zwrKe8ICrcIQB2', # Alex Arellano\n",
    "'2HAXLm7OCK8VHC', # Luam Rincon\n",
    "'c9r65cbijsca55', # Emily Torres Luevano\n",
    "'k03oyt4ddgd9au', # Vicky Calderon\n",
    "'P0CWy9vUnIHhkO', # Leslie Flores\n",
    "'t21hvz9jdl15vt', # Ricardo Torres\n",
    "'u-56-5837',      # Angel Sanchez\n",
    "'5esYyfuBwTApq8', # Raquel Alvarado\n",
    "'fncmu10iwxbded', # Stephanie Salgado Altimarano\n",
    "'c-167138',       # Ania Jimenez\n",
    "'u-56-1841',      # Liam Gonzalez\n",
    "'vIHtcC9AjNewEl', # the Unknown Vocero\n",
    "'u-56-19305',     # Cassandra Casas\n",
    "'u-56-21499'] #Yesenia Perez\n",
    "\n",
    "departed_names = [\\\n",
    "'Alan Nichols',  # Al Nichols\n",
    "'Fabian Maldonado', # Fabi,\n",
    "'Jake Pena', # Jake Pena\n",
    "'Gilbert Nunez', # Gilbert Nunez\n",
    "'Emily Firlinger', # Emily Firlinger\n",
    "'Jennifer Estrada', # Jennifer Estrada\n",
    "'Dummy Account', # Dummy Account\n",
    "'Ray Pugh', # Ray Pugh\n",
    "'Clay Perry', # Clay Perry\n",
    "'Allison Vasquez-Lovell',     # Allison Vasquez-Lovell\n",
    "'Jose Rivera', # Jose Rivera\n",
    "'Ruben Ramos', # Ruben Ramos\n",
    "'Minerva Cornejo', # Minerva Cornejo\n",
    "'Alex Arellano', # Alex Arellano\n",
    "'Luam Rincon', # Luam Rincon\n",
    "'Emily Torres Luevano', # Emily Torres Luevano\n",
    "'Vicky Calderon', # Vicky Calderon\n",
    "'Leslie Flores', # Leslie Flores\n",
    "'Ricardo Torres',\n",
    "'Angel Sanchez',\n",
    "'Raquel Alvarado',\n",
    "'Stephanie Salgado Altimarano',\n",
    "'Ania Jimenez',\n",
    "'Liam Gonzalez',\n",
    "'the Unknown Vocero',\n",
    "'Cassandra Casas',\n",
    "'Yesenia Perez' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class to hold data about directors, supervoceros, and voceros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Organizer(object):\n",
    "    def __init__(self, first_name, last_name, role, eid, parent_eid, last_used_empower, \n",
    "            personal_voter_count = 0, downstream_voter_count = 0, downstream_leader_count = 0):\n",
    "        self.first_name = first_name.strip()\n",
    "        self.last_name = last_name.strip()\n",
    "        self.full_name = ' '.join([self.first_name, self.last_name])\n",
    "        self.role = role.strip()\n",
    "        self.eid = eid\n",
    "        self.parent_eid = parent_eid\n",
    "        self.last_used_empower = last_used_empower\n",
    "        self.organizer_list = []\n",
    "        self.personal_voter_count = personal_voter_count\n",
    "        self.downstream_voter_count = downstream_voter_count\n",
    "        self.downstream_leader_count = downstream_leader_count\n",
    "        \n",
    "    def add_organizer(self, organizer):\n",
    "        self.organizer_list.append(organizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for data cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitTime(theTime):\n",
    "    if isinstance(theTime, int) or isinstance(theTime, float):\n",
    "        if np.isnan(theTime):\n",
    "            return beginningOfTime.date()\n",
    "        return pd.to_datetime(time.strftime(\"%Y-%m-%d\",time.gmtime(int(theTime/1000)))).date()\n",
    "    if not theTime or theTime.isspace():\n",
    "        return beginningOfTime.date()\n",
    "    if 'T' in theTime:\n",
    "        date, time = theTime.split('T')\n",
    "    elif ' ' in theTime:\n",
    "        date, time = theTime.split(' ')\n",
    "    date_dt = pd.to_datetime(date)\n",
    "    return date_dt.date()\n",
    "\n",
    "def IsBlank(s):\n",
    "    if isinstance(s, float) or isinstance(s, int): return True\n",
    "    try:\n",
    "        return bool(not s or s.isspace())\n",
    "    except ValueError:\n",
    "        print(type(s))\n",
    "\n",
    "def IsNotBlank(s):\n",
    "    if isinstance(s, float) or isinstance(s, int): return False\n",
    "    return bool(s and not s.isspace())\n",
    "\n",
    "def ParsePhoneUS(phone_number):\n",
    "    default_phone = ''\n",
    "    if isinstance(phone_number, float) or isinstance(phone_number, int): return default_phone\n",
    "    assert(isinstance(phone_number, str))\n",
    "    if phone_number == 'None' or phone_number == 'nan' or IsBlank(phone_number): return default_phone\n",
    "    if (len(phone_number) > 10 and phone_number[0] == '+'):\n",
    "        phone_number = phone_number[1:]\n",
    "    if(len(phone_number) > 10 and phone_number[0] == '1'):\n",
    "        phone_number = phone_number[1:]\n",
    "    if len(phone_number) > 10  and phone_number[-1] == '0':\n",
    "        phone_number = phone_number[:10]\n",
    "    try:\n",
    "        my_number = phonenumbers.parse(phone_number, region = 'US')\n",
    "        return phonenumbers.format_number(my_number, phonenumbers.PhoneNumberFormat.NATIONAL)\n",
    "    except phonenumbers.NumberParseException:\n",
    "        return default_phone\n",
    "\n",
    "def CleanPhone(df, phone_column = 'phone'):\n",
    "    \"\"\"\n",
    "    Convert a ten-digit string to a more readable (xxx) xxx-xxxx format\n",
    "    Args:\n",
    "        df (Pandas DataFrame)\n",
    "        phone_column (str, optional): Name of the column where\n",
    "        the phone numbers are found. Defaults to 'phone'.\n",
    "\n",
    "    Returns:\n",
    "        Inpuyt DataFrame with specified column converted\n",
    "    \"\"\"    \"\"\"\"\"\"\n",
    "    column_list = list(df.columns)\n",
    "    default_phone = ''\n",
    "    if phone_column in column_list:\n",
    "        indx = column_list.index(phone_column)\n",
    "        df[phone_column] = df[phone_column].astype(str)\n",
    "        df[phone_column] = df[phone_column].fillna(default_phone)\n",
    "        df['phone_clean'] = df[phone_column].apply(lambda x : ParsePhoneUS(x))\n",
    "        df.drop(columns = [phone_column], inplace = True)\n",
    "        df.rename(columns = {'phone_clean':phone_column}, inplace = True)\n",
    "        df.insert(indx, phone_column, df.pop(phone_column))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, do some cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file...\n",
      "Data loaded, elapsed time: 4.19 seconds.\n",
      "Loaded 30622 records.\n",
      "Cleanup complete.\n"
     ]
    }
   ],
   "source": [
    "data = InitializeDataFrames(path, data_file, {})\n",
    "if not data.empty:\n",
    "    print('Loaded', len(data), 'records.')\n",
    "    \n",
    "columns_to_keep = ['Parent EID', 'EID', 'Role','First Name', 'Last Name', \n",
    "    'Phone', 'Created At','Last Used Empower At']\n",
    "\n",
    "columns_renamed = ['ParentEID', 'EID', 'Role','FirstName', 'LastName', \n",
    "    'Phone', 'CreatedAt','LastUsedEmpowerAt']\n",
    "\n",
    "data = data[columns_to_keep]\n",
    "data.rename(columns=dict(zip(columns_to_keep, columns_renamed)), inplace=True)    \n",
    "\n",
    "data['CreatedAt'] = data['CreatedAt'].apply(lambda x : SplitTime(x)) \n",
    "data['LastUsedEmpowerAt'] = data['LastUsedEmpowerAt'].apply(lambda x : SplitTime(x)) \n",
    "\n",
    "data.fillna({'FirstName':' ', 'LastName': ' ', 'ParentEID':' '},  inplace=True)\n",
    "data = CleanPhone(data, phone_column='Phone')\n",
    "print(\"Cleanup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the voters from the leaders, and pull out the leaders who are no longer with us.  We want them out of the way in order to focus on the people below them in the hierarchy who still could potentially be activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voter count: 29000\n",
      "initial leader count: 1622\n",
      "activated leader count: 847\n",
      "activated and present leader count: 825\n"
     ]
    }
   ],
   "source": [
    "## subset the leaders and the contacts\n",
    "leaders = data.loc[data['Role'].isin(organizers)]\n",
    "voters = data.loc[data['Role'] == 'Contact']\n",
    "print('voter count:',len(voters))\n",
    "\n",
    "## over the years, many leaders signed onto the system once and never did anything. We want to consider only\n",
    "## people who signed on at least twice, so their last use date is later than their start date.\n",
    "print('initial leader count:', len(leaders))\n",
    "activated_leaders = leaders.loc[leaders['LastUsedEmpowerAt'] > leaders['CreatedAt']][columns_renamed]\n",
    "print('activated leader count:', len(activated_leaders))\n",
    "\n",
    "activated_directors = activated_leaders.loc[(activated_leaders['Role'] == 'Director') & (~activated_leaders['EID'].isin(departed_eids))]\n",
    "activated_organizers = activated_leaders.loc[(activated_leaders['Role'] == 'Organizer') & (~activated_leaders['EID'].isin(departed_eids))]\n",
    "activated_volunteers = activated_leaders.loc[(activated_leaders['Role'] == 'Volunteer') & (~activated_leaders['EID'].isin(departed_eids))]\n",
    "\n",
    "#do this so we can have a blank parent for building the tree\n",
    "activated_directors.loc[:,'ParentEID'] = ''\n",
    "\n",
    "leaders = pd.concat([activated_directors, activated_organizers, activated_volunteers])\n",
    "leaders['FullName'] = leaders['FirstName'] + ' ' + leaders['LastName']\n",
    "leaders.reset_index(inplace=True, drop=True)\n",
    "print('activated and present leader count:', len(leaders))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we could print out a spreadsheet of the leaders and the orphans, and start making phone calls. \"AnalyzeEmpowerRVP.ipynb\" demonstrates that.  Instead, we'll next build a tree of the leaders, and a graph for the network of one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_eid = 'u-56-21617'\n",
    "multi = leaders.set_index(['ParentEID','EID'])\n",
    "\n",
    "## all of the leaders whose parent is the selected director\n",
    "df_sam = multi.loc[multi.index.get_level_values('ParentEID') == sam_eid].sort_values(by = ['Role','LastUsedEmpowerAt'], ascending = [True, False])\n",
    "df_sam.reset_index(inplace=True)\n",
    "\n",
    "## also add the selected director\n",
    "df_sam = pd.concat([df_sam, leaders.loc[leaders['EID'] == 'u-56-21617']])\n",
    "\n",
    "## add the volunteers whose parents are children of the selected director\n",
    "for row in df_sam.itertuples():\n",
    "    if row.Role == 'Organizer':\n",
    "        df_local = leaders.loc[leaders['ParentEID'] == row.EID]\n",
    "        df_sam = pd.concat([df_sam, df_local])\n",
    "\n",
    "voter_counts = []\n",
    "gb = voters.groupby('ParentEID', as_index=False).size()\n",
    "\n",
    "## get a voter count for each parent\n",
    "for row in df_sam.itertuples():\n",
    "    try:\n",
    "        voter_counts.append(gb.loc[gb['ParentEID'] == row.EID]['size'].values[0])\n",
    "    except IndexError as e:\n",
    "        voter_counts.append(0)\n",
    "    \n",
    "df_sam['PersonalVoterCount'] = voter_counts   \n",
    "df_sam['DownstreamVoterCount'] = df_sam['PersonalVoterCount']\n",
    "df_sam['DownstreamLeaderCount'] = 0\n",
    "\n",
    "df_sam_org = df_sam.loc[(df_sam['Role'] == 'Organizer') ]\n",
    "\n",
    "## downstream voter count for directors and organizers is the sum of their personal voter count\n",
    "## and the voter counts of their children\n",
    "for row in df_sam_org.itertuples():\n",
    "    local_leaders = leaders.loc[leaders['ParentEID'] == row.EID]\n",
    "    df_sam.loc[row.Index, 'DownstreamLeaderCount'] = len(local_leaders)\n",
    "    voter_count = row.PersonalVoterCount\n",
    "    for leader in local_leaders.itertuples():\n",
    "        try:\n",
    "            voter_count += gb.loc[gb['ParentEID'] == leader.EID]['size'].values[0]\n",
    "        except IndexError as e:\n",
    "            voter_count += 0\n",
    "    df_sam.loc[df_sam['EID'] == row.EID,'DownstreamVoterCount'] = voter_count\n",
    "\n",
    "## sum all for the director\n",
    "df_sam.loc[df_sam['EID'] == 'u-56-21617','DownstreamLeaderCount'] = df_sam['DownstreamLeaderCount'].sum()\n",
    "df_sam.loc[df_sam['EID'] == 'u-56-21617','DownstreamVoterCount'] = df_sam['DownstreamVoterCount'].sum()\n",
    "\n",
    "df_sam.sort_values(by = ['Role','ParentEID', 'LastUsedEmpowerAt'], ascending = [True, True,False], inplace=True)\n",
    "df_sam.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## seems like a reasonable way to organize this\n",
    "multi = df_sam.set_index(['ParentEID','EID'])\n",
    "\n",
    "# with pd.ExcelWriter('SamsRVPNetwork.xlsx') as writer:  # doctest: +SKIP\n",
    "#     multi.to_excel(writer, sheet_name='Sheet1')\n",
    "            \n",
    "## load the organizers into the dictionary\n",
    "organizer_dict = {}\n",
    "for row in df_sam.itertuples():\n",
    "    try:\n",
    "        organizer = Organizer(row.FirstName, row.LastName, row.Role, row.EID, row.ParentEID, row.LastUsedEmpowerAt, row.PersonalVoterCount, row.DownstreamVoterCount, row.DownstreamLeaderCount)\n",
    "        organizer_dict[row.EID] = organizer\n",
    "        ## load their children too\n",
    "        if row.Role == 'Organizer':\n",
    "            local_leaders = activated_volunteers.loc[activated_volunteers['ParentEID'] == row.EID]\n",
    "            for leader in local_leaders.itertuples():\n",
    "                try:  \n",
    "                    organizer = Organizer(leader.FirstName, leader.LastName, leader.Role, leader.EID, leader.ParentEID, leader.LastUsedEmpowerAt, leader.PersonalVoterCount, leader.DownstreamVoterCount, leader.DownstreamLeaderCount)  \n",
    "                    organizer_dict[leader.EID].add_organizer(organizer)\n",
    "                except Exception as e:  ## this will happen when the leader.EID is not in the dict\n",
    "                    pass\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        \n",
    "## hook up the parent pointers\n",
    "keys = organizer_dict.keys()\n",
    "for key in keys:\n",
    "    current = organizer_dict[key]\n",
    "    while current.parent_eid in keys:\n",
    "        parent = organizer_dict[current.parent_eid]\n",
    "        parent.add_organizer(current)\n",
    "        current = parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping the voters by parent eid allows us to assign a voter count to the vocero/supervocero/director who is the parent node of the voter in the tree.  The high orphan voter count is caused by the departure of the leaders from the system.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrating how to make a title for a node in the graph we'll produce below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_map = {'Organizer': 'SuperVocero', 'Director': 'Director', 'Volunteer': 'Vocero'}\n",
    "def make_title(organizer):\n",
    "    full_name = ' '.join([organizer.full_name +':', role_map[organizer.role]])\n",
    "    last_used = organizer.last_used_empower\n",
    "    personals = organizer.personal_voter_count\n",
    "    downstreams = organizer.downstream_voter_count\n",
    "    row0 = full_name\n",
    "    row1 = 'Last Used Empower: ' + str(last_used)\n",
    "    row2 = 'Personal Voter Count: ' + str(personals)\n",
    "    row3 = 'Downstream Voter Count: ' + str(downstreams)\n",
    "    return '\\n'.join([row0, row1, row2, row3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create nodes and edges from the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddNodesToGraph(graph, organizer, current_names, ndx):\n",
    "    if organizer.eid in current_names:\n",
    "        return\n",
    "    current_names.add(organizer.eid)\n",
    "    title = make_title(organizer)\n",
    "    if organizer.last_used_empower > campaignStartDate: \n",
    "        color = 'blue'\n",
    "    else: color = 'red'\n",
    "    graph.add_node(organizer.full_name,  borderWidth = 10,  title = title,  color = color, borderColor = 'blue',\n",
    "            font = '10px arial black', size = organizer.personal_voter_count)\n",
    "    for item in organizer.organizer_list:\n",
    "        graph.add_edge(organizer.full_name, item.full_name)\n",
    "        AddNodesToGraph(graph, item, current_names, ndx+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a director, show the supervoceros/voceros below her.  Diameter of the node correlates with size of their voter list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of names: 58\n"
     ]
    }
   ],
   "source": [
    "current_names = set()\n",
    "G = nx.Graph()\n",
    "organizer = organizer_dict[\"u-56-21617\"] # Samanta\n",
    "AddNodesToGraph(G, organizer, current_names,0)\n",
    "\n",
    "print('number of names:', len(current_names))\n",
    "\n",
    "net = Network(  directed = True, width=1000, height=600)\n",
    "net.from_nx(G)\n",
    "net.show(\"example.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heroku_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
